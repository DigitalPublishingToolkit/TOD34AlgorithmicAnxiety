---
Pr-id: Algorithmic Anxiety: A Kierkegaardian Inquiry into the Imaginary of Possibility
P-id: Theory on Demand
A-id: 32
Type: article
Book-type: anthology
Anthology item: article
Item-id: 02
Article-title: introduction
Article-status: accepted
Author: Patricia de Vries
Rights: CC BY-NC 4.0
...


# Introduction: From Algorithms to Algorithmic Culture

For a long time, artistic engagement with algorithms was marginal in
contemporary art.

Over the past eight years, however, a growing number of artists and
critical practitioners have become engaged with algorithms, resulting in
algorithmic theatre, bot art, and algorithmic media and performance art
of various kinds, which thematize the dissemination and deployment of
algorithms in everyday life. The numerous art exhibitions that have been
curated over the past years in art institutions, at festivals, in
galleries and at conferences — both large and small — in Europe, the
Americas, Canada, and in China, reflect this rising prominence of
algorithmic art. These exhibitions aim at imagining, representing and
narrativizing aspects of what is called algorithmic culture: for
instance, in exhibitions that address the modulation of behavior and
algorithmic governance; shows on algorithmic capitalism and data
surveillance; shows on self-quantification; as well as shows on
information technology and cybernetic culture and human and machine
relations in general. Indeed, one might say, in the spirit of Langdon
Winner, that ‘algorithm’ is a word whose time has come. If theorists
of media and technology are to be believed, we live in an ‘algorithmic
culture’.[^intro_1] [^intro_2] [^intro_3]

Algorithms sort, search, recommend, filter, recognize, prioritize,
predict and decide on matters in a range of fields. They are embedded in
high-frequency trading in the financial markets and in predicting crime
rates through data profiling, for instance. They are deployed to analyze
traffic, to detect autoimmune diseases, to recognize faces, and to
detect copyright infringements. Mundane aspects of our lives, such as
work, travel, play, consumption, dating, friendships, and shopping are
also, in part, delegated to algorithms; they've come to play a role in
the production of knowledge, in security systems, in the partners we
choose, the news and information we receive (or not), the politicians we
vote for, the jobs we get (or not). They also help automate routine
jobs, and they are used in drone warfare, education evaluations, social
services, and in numerous other fields. A time of ubiquitous algorithmic
computing is ‘firmly established’, writes Rob Kitchin.[^intro_4]

Ted Striphas describes this developing algorithmic culture as a ‘shift’
which first began 30 years ago, as humans increasingly started to
delegate ‘the work of culture – the sorting, classifying and
hierarchizing of people, places, objects and ideas – to computational
processes’.[^intro_5] Aspects of everyday life are increasingly delegated to
algorithms and accompanied by an algorithmic type of rationality.[^intro_6]
‘The algorithmic’, Paul Dourish observes, has become incorporated into
broader and ongoing conversations about how our lives are shaped and
organized.[^intro_7] Algorithms are part of mechanisms that privilege
quantification, proceduralization and automation in human endeavors,
Tarleton Gillespie argues.[^intro_8] Further, Taina Bucher contends that as
everyday life increasingly takes place in and through an algorithmic
media landscape, algorithms co-produce social life and political
practices.[^intro_9] ‘In ranking, classifying, sorting, predicting, and
processing data, algorithms are political in that they help to make the
world appear in certain ways rather than others’.[^intro_10] They do so, to an
extent, in ways that are invisible to the human eye — an effect of,
amongst other things, proprietary laws and regulations, computational
scale, speed and complexity. This is why Gillespie argues algorithms
remain outside human grasp, that there is something ‘impenetrable’ about
their performance.[^intro_11] Their pervasiveness, the claim that algorithms
shape our socio-technical world, the alleged ‘merging of algorithms into
the everyday’, and the notion that they are ‘taking decisions out of the
hands of human actors’ are all taken to be indicative of the ways
algorithms have become a critical infrastructural element of
contemporary life.[^intro_12] Like infrastructure, algorithms have become a
key site and gatekeepers of power and power relations.[^intro_13]

Altogether, this has made for an intriguing art object — invisible yet
omnipresent, proprietary yet pervasive, and with assumed socio-political
powers that co-produce our lives — and a burgeoning field in
contemporary art. The claim that algorithms shape, organize and
co-produce everyday life, in ways that vary from the seemingly quotidian
to the heavily politicized, has not only inspired artists, it has also
given impetus to anxieties about the present and future of algorithmic
culture in light of these developments. It seems ‘the algorithmic’ and
‘algorithmic culture’ have become shorthand for a nexus of concerns
about the entanglement of the social and the algorithmic. Having visited
numerous exhibitions thematizing algorithmic culture, what I have found
striking is the high volume of artistic engagements with facial
recognition algorithms, trading algorithms and search engine algorithms.
It seems these types of algorithms have garnered more artistic responses
than other types of algorithms. What is more, a limited number of
artworks that engage explicitly with these three types of algorithms
have been circulating widely; they have been included again and again
and again in a wide range of thematized group exhibitions on different
aspects of algorithmic culture throughout Europe, Canada, and the
Americas. Some of the artists of these works received a great deal of
attention in the international press and have given numerous lectures at
international art and digital culture conferences, festivals, and other
public events. This attention on facial recognition algorithms, trading
algorithms and search engine algorithms might not be surprising. After
all, facial recognition algorithms, trading algorithms and search engine
algorithms are associated with a range of concerns and uncertainties
about the deployment, future developments, and possible implications of
algorithms. Facial recognition algorithms are associated with repressive
political regimes, with influencing people’s personal decisions, with
amplifying racism, sexism and homophobia, with deep fake videos, and
with preempting political dissent. Trading algorithms are linked to the
global financial crisis, volatility on the financial markets, and are
said to undermine open societies and markets. Search algorithms are
blamed for filter bubbles, the spread of fake news, and the
corporatization of online information. Taken together, these three types
of algorithms address significant supra-individual anxieties of this
decade: socio-political uncertainty, the global economic crisis and
ongoing recession, the centralization and financialization of access to
online information, and political polarization and instability.

However, what *underpins* of these anxieties and why these three types
of algorithms form the subject of critique is rarely interrogated, less
so when this criticism takes the form of artistic portrayals. This is
one issue that I wish to address.

This renewed artistic attention to algorithms in general — and facial
recognition algorithms, trading algorithms and search engine algorithms
in particular — would not have surprised Marshall McLuhan, who wrote in
*Understanding Media: The Extensions of Man* that reflections on new
media technologies require the artistic eye: ‘The serious artist is the
only person able to encounter technology with impunity, just because he
is an expert aware of the changes in sense perception’.[^intro_14] Such a
statement might ring too Romantic for our time. I do not agree with his
notion that *only* artists can understand the days and age we live in.
However, there is a shortage of scholarship that relates algorithms to
the broader artistic and cultural contexts in which they are embedded.
Reflections on algorithmic culture require materializing what is,
mostly, invisible, and this is done, *in part*, by artists from various
perspectives and disciplines. What is lacking is an analysis of how the
algorithm is *imagined*, represented, and narrativized by artists, which
can also be understood as an effect of algorithms in and of itself.
Artworks are sites of meaning on which ideas and stories about
algorithms are circulated, stretched, organized, and shaped. Therefore,
I use prominent artistic representations of facial recognition
algorithms, trading algorithms and search algorithms as the entry point
into an exploration of the constituents of the anxieties braided around
these algorithms.

Focusing on the artistic portrayals of algorithmic entanglements takes
us away from questions revolving around what, when, and where algorithms
*are*. While acknowledging that technical details about algorithms are
important, I aim to respond to the idea that algorithms ‘do’ things
beyond their technical capabilities. There is nothing novel about
algorithms — depending on one's definition, they can be traced back to
Babylonian times. The question we must therefore ask is why algorithms
arise *now* as objects of concern, not just for artists but for
academics and numerous commentators in a variety of fields. Should we
see them as synonymous with the anxieties about Big Tech? What is the
object of concern, the input or the output of algorithms? And which came
first: the data or the algorithm? If data and algorithms are mutually
dependent, can we analyze them separately? Should we perhaps write a
typology of all existing types of algorithms, down to the technical
minutiae of lines of computer code? Do we need to study their formal
automation structures, or rather the mathematical formulae with which
they calculate? Should we instead study the instructions for navigation,
the parameters, the encoded procedures that transform input data into
output data? Or should we study the entire software ecology that
supports them? Should we historicize the algorithm and situate it within
the persistent modernist desire for mechanization and automation? Are
algorithms agents, objects or artefacts, or merely automated statistics?
Particular algorithms often operate as part of a collection of
algorithms that are part of networked systems, which raises the
question: *Where* is ‘the algorithm’? Plus, algorithms are constantly
tweaked and honed, and thus constantly change. Thus: *When* is ‘the
algorithm’? Put simply: ‘the algorithm’ is more than the sum of its
parts, it stands for more than its technical capabilities. As David Beer
puts it:

> The algorithm is now a cultural presence, perhaps even an iconic
> cultural presence, not just because of what they can do but also
> because of what the notion of the algorithm is used to project. \[W\]e
> need to develop an analysis of the cultural prominence of the notion
> of the algorithm, what this stands for.[^intro_15]

These questions inform the investigation of algorithms in this book.
Nevertheless, the approach to algorithms it will take is slightly
different or perhaps even unexpected.

Outstanding work on aspects of algorithmic culture has been done over
the years. Drawing on software studies, philosophy of technology,
ethics, media studies, race and gender studies, decolonial studies, STS,
and social sciences, thorough critical research has been conducted on
algorithmic culture from a wide variety of disciplines.[^intro_16] However,
one crucial aspect of algorithmic culture that has yet to be studied by
scholars working in these fields is the anxieties that underpin the
cultural prominence of algorithms. This aspect of the algorithm is a
recurrent theme of commentary on these computational processes. It is
also central to our experience of algorithmic culture. It therefore
merits closer reading. My investigation of the algorithm will focus on
the anxieties that undergird our relation to them. To analyze the
anxieties that surround algorithms, I propose that the work of Søren
Kierkegaard — one of the first theorists of anxiety — can help us to
investigate and to analyze different anxieties about algorithmic culture
critically. Much has been written on Kierkegaard's conception of
anxiety, but it has not been applied to anxieties around algorithmic
culture. Doing so obviously brings his work into a context that it could
not have anticipated, yet one in which it will be useful nonetheless.

In *The Concept of Anxiety*, Kierkegaard argues that anxiety, different
from fear, has no object and no determinate character.[^intro_17] When one
feels anxious, one’s anxiety is caused by nothing in particular or a
‘not-yet’ of unknown character. Anxiety is a term for a concept, an
experience and a response to events and phenomena that are not knowable,
not fully graspable, ambiguous or vague. One is not anxious about
‘persons’ or ‘finitudes’, Kierkegaard explains.[^intro_18] One is also not
anxious about yesterday either because anxiety is future-oriented.
Though it may be felt in the here and now, in your body, anxiety points
to the future, to the not yet and the yonder. We are anxious about
possible future events and phenomena that we cannot anticipate, know, or
predict. It is the radical openness of the future or, put another way,
the inability to fully comprehend or know the future, which conditions
anxiety.

This radical openness of the future is what Kierkegaard calls
possibility or the possible. Kierkegaard writes that when anxiety
seizes, one is seized by the possible. The possible is about future
possibility — a condition that is not. Therefore, he argues, possibility
— and, counterintuitively, not *im*possibility — ‘is the most difficult
of all categories’.[^intro_19] He writes: ‘In possibility all things are
equally possible and anyone truly brought up by possibility has grasped
the terrifying just as well as the smiling.’[^intro_20] Everything is possible
within the possible, and ‘everything’ includes the unthinkable,
unknowable and unimaginable. If everything were not possible, there
would be no possibility, and the future would then be to a great extent
calculable, predictable, probable, which does not mean that people do
not try to predict the future or aim to reduce risks with the help of
calculations and probabilities. However, that does not change anything
about the fundamental openness of the future, according to Kierkegaard,
as ‘\[a\]nxiety is freedom’s possibility’.[^intro_21] Without possibility
there would be no anxiety, because ‘anxiety is freedom's actuality as
the possibility of possibility’.[^intro_22] Anxiety is about what is possible,
and what is possible is fundamentally unknown to mortals. Further,
‘learning to be anxious’ means to not avoid it altogether nor being
ruined by it, but to learn to ‘live through’ it.[^intro_23] Importantly, it
entails being aware ‘that absolutely nothing can be demanded of life,
and that horror, perdition, and annihilation live next door to every
human being’.[^intro_24] It has to do with the vague awareness that sudden
‘cataclysmic events’ are as much a part of life as the moments of
serenity and joy.[^intro_25]

Further, for Kierkegaard anxiety is both an ontological and
epistemological concept. In *The Concept of Anxiety*, he argues that all
epistemology is rooted in anxiety and those moments of anxiety are
fundamental to human existence. Importantly, anxiety is not merely a
personal feeling; it is grounded in the social, Kierkegaard explains in
*The Present Age: On the Death of Rebellion*.[^intro_26] Referring to
Kierkegaard, and writing on anxiety, Sianne Ngai explains this
connection between anxiety, ontology and epistemology in *Ugly Feelings*
as follows:

> \[T\]here is an indissociable relation between affect and concept in
> which every cognitive structure is said to presuppose a mood — so much
> so that an error in the modulation becomes just as disturbing as an
> error in the development of thought.[^intro_27]

Anxiety is also a social emotion. Ngai explains:

> \[F\]eelings are fundamentally ‘social’ as the institutions and
> collective practices that have been the more traditional objects of
> criticism (as Raymond Williams was perhaps the earliest to argue in
> his analyses of ‘structures of feelings’) \[…\] and “infrastructural”
> in its effects.[^intro_28]

Understood this way, anxiety gives shape to the ways in which the
entanglement of the social and the algorithmic is conceived, while this
entanglement also harbors beliefs and structures of feeling and
understanding. It pertains to possible future forms of being, presence
and knowledge in entanglement with algorithms that are uncertain or
unknown to us. The prominent artistic engagements I focus on are
emblematic of ways of perceiving the entanglement with algorithms that
can be described as structured by anxiety. What I will call ‘algorithmic
anxiety’ refers to the ways in which anxiety — as both an ontological
and epistemic concept — is shaped by anxieties about the future of
algorithmic culture, which shapes perceptions of algorithms in the
present and which, in turn, is reflected in prominent contemporary
artworks that address specific practices of facial recognition, trading
algorithms and search algorithms.

Of course, one might argue that the anxiety around algorithms, in
general, is the umpteenth version of the age-old trope of the fear of
what Langdon Winner called autonomous technology. Another might claim
that algorithmic anxiety is nothing more than a reassertion of a type of
Romantic humanism which arises as a result of socio-technical
developments that put pressure on the boundaries of a particular
symbolic order. Indeed, anxiety about algorithms seems to be synonymous
with the anxiety about the totality of information technology, with
networks of ultra-speed data travelling and the management of its
protocols by state institutions and for-profit corporations. Some could
argue that anxiety around algorithms is part of the anxiety about the
‘societies of control’[^intro_29] or ‘control societies’[^intro_30]. Furthermore,
others might say algorithms are imbued in histories of war-time
machinery and colonialism, which intersect with mechanisms of
bureaucratization and the management and control of human endeavors, as
well as with the long histories of statistics, accounting, and
quantification. This might be true, in part or in whole; I do not mean
to argue against this. However, to acknowledge these claims does not
address the question of why specific aspects and implementations of
algorithms are at the forefront of critique rather than others. More
specifically, it leaves open how specific algorithms are imagined such
that they are generative of different anxieties that seem to reach far
beyond their specific and respective technological capabilities. Facial
recognition algorithms trigger different anxieties than search
algorithms, which trigger different anxieties than trading algorithms,
which trigger different anxieties than facial recognition and search
algorithms.

This leads me to the central question that structures this book: What
anxieties are interwoven with algorithms as represented within prominent
art practices and how is the possible constituted therein?

The concept of algorithmic anxiety will be developed in the following
chapters. To flesh out this concept, I use what is called a
‘concept-based methodology’ to read prominent artistic engagements with
facial recognition, trading algorithms and search algorithms alongside
Kierkegaard’s conception of anxiety.[^intro_31] Algorithmic anxiety builds on
Kierkegaard’s conception of anxiety, yet, by using it to think
contemporary algorithmic culture, inevitably also moves beyond it. I do
not use Kierkegaard’s conception of anxiety as a looking glass through
which artworks are analyzed or explained. Rather than presupposing what
algorithmic anxiety might be, I will develop a concept of algorithmic
anxiety through its engagements with artworks that engage with
algorithms and the interplay between these artworks and Kierkegaard's
conception of anxiety. In order to think further about its implications
in today’s algorithmic culture, concepts from the fields of philosophy,
science and technology studies, algorithmic studies, comparative
literature, as well as from cultural studies and media studies, will be
put into dialogue with concepts and motifs present in the artworks. This
concept-based method helps to understand why specific types of
algorithms inspire anxiety more than others, and how algorithms gain
meaning beyond their input and output, the code they run on, the data
they process, or the specific corporate and technical infrastructural
contexts in which they operate. I aim to contribute to discussions about
how the entanglement of the social and the algorithmic is perceived, in
different instances and from different perspectives, such that it evokes
anxiety.

Chapter 1 comprises the conceptual framework of this book. I first
introduce key anxieties discussed in academic studies on the
entanglement of humans with facial recognition, trading algorithms and
search algorithms. I then move on to Kierkegaard's conception of
anxiety. Since I aim to contribute to a better understanding of the
underpinning of the anxieties about specific types of algorithms, the
first question I want to raise is: What does it mean to speak of anxiety
in Kierkegaard's conception of the term? Chapter 1 provides an outline
of Kierkegaard's account of anxiety and, specifically, how it is
conceptualized in relation to his other vital concepts that inform his
work on anxiety: the self, faith, knowledge and the possible. Chapter 1
closes with a preliminary sketch of the concept of algorithmic anxiety.

After this preliminary sketch of some of the critical constituents of
algorithmic anxiety, the subsequent Chapters 2, 3 and 4 are each
organized around an artistic portrayal of a particular algorithmic
process: facial recognition, trading and search algorithms,
respectively. Algorithmic anxiety in contemporary art takes different
forms. In one more dominant trend, artists reflect on how algorithmic
culture affects conceptions of self and values like freedom,
transparency, autonomy, or objectivity. Other artists seek to
materialize the alleged immateriality of trading algorithms. Some mock
the trust in algorithmic computing; others soak it up. Yet others deploy
algorithms to specific political ends to criticize the rationality
behind some of their features. Each of these artistic portrayals of
algorithms performs and produces different anxieties. Each of these
chapters is framed by a close reading of a number of these artworks. I
develop the concept of algorithmic anxiety through a close reading of
the recurring motifs and concepts in particular artistic imaginaries,
drawing on masks and camouflage (Chapter 2); hybrids and specters
(Chapter 3); and collectors and collections (Chapter 4). Artists design
face masks and camouflage wear, evoke specters and hybrids, and imagine
infinite collections to narrativize and imagine the evolving and
ambiguous phenomena of ‘the algorithmic’. The inherent ambiguity of the
range of concepts and motifs that I engage with is part of the dynamic
of algorithmic anxiety that I will contextualize and conceptualize.

It has to be noted that the artworks I have selected for analysis are
preponderantly made by Western artists who have received a great deal of
critical attention and who have been exhibited repeatedly in art
exhibitions about algorithmic culture primarily — but not exclusively —
in Western Europe and the U.S. This focus on Western artists in Western
exhibitions is for reasons of access: over the past seven years, I have
visited numerous exhibitions on algorithmic culture, mainly in Western
Europe and in the U.S., that reflected an anxiety that one could also
find in popular and mainstream Western media reports — written in
languages I can read — on the developments of algorithmic culture. That
said, the examples covered provide a thorough cross-section of
contemporary art about algorithms.

Chapter 2 explores mask and camouflage wear designed by artists in an
attempt to thwart off and criticize facial recognition algorithms. It
focuses on Zach Blas’s *Facial Weaponization Suite* (2012), Adam
Harvey’s *HyperFace* (2017), and Sterling Crispin’s *Data-Masks* (2014),
offering a reading of these prominent artworks in relation to
Kierkegaard’s conception of the self as a synthesis between the finite
and the infinite. The algorithmic capture of the face causes anxiety
partly because of the powerful capabilities with which facial
recognition technology is associated. In this chapter, I explore how the
self is performed in these mask and camouflage works and how a
Kierkegaardian conception of the self presents a play with relations
between self, environment and the algorithmic medium of capture.
Combined with a Kierkegaardian notion of the self as a relational
synthesis, masks and camouflage show the possibilities inherent in
emphasizing different forms of being and relating — such as
interdependency, community, collaboration, and collectivity — which may
defy anxieties evoked by facial recognition technology.

Chapter 3 centers on the close reading of prominent artworks that engage
with trading algorithms. Algorithmic trading causes anxiety in part
because the infrastructure of trading algorithms is conceived as an
invisible and impenetrable black box, impervious to change. This chapter
uses Rita Felski’s concepts of ‘digging down’ and ‘standing back’ to
distinguish between two popular artistic approaches to trading
algorithms. Artists that ‘stand back’ visualize aspects of the
infrastructure of the black box of finance, such as server racks, cables
of different kinds, and market index graphs. This rendering visible of
supposedly invisible aspects of the black box of finance is perceived as
a key to grasp and open it. The second approach is characterized by
artists that in various ways tinker with or reenact the inner workings
of aspects algorithmic trading. Both tend to focus on, and add emphasis
to, a limited set of infrastructural aspects of algorithmic trading.
This is followed by an analysis of a third approach which focuses on a
spectral imaginary of trading algorithms, exemplified in this chapter by
Emma Charles’ experimental video artwork, *Fragments on Machines*
(2013), and Femke Herregraven’s work *Pull everything, pull everything*
(2018). Their spectral imaginary of trading algorithms focuses on the
broader relational context within which algorithmic trading is embedded.
What is more, their spectral representations allude to subversive and
possibly catastrophic events under which change becomes possible. To
unpack the relation between catastrophe and change, I read these
artworks alongside Kierkegaard’s notion of the possible.

Chapter 4 engages with the anxieties that Google's search engine evokes.
This chapter focuses on Google primarily because it is the most used
search engine, at least in Europe and the U.S.: this service evokes
anxiety about the abuse of aggregated data and the for-profit logic
behind the algorithmically ranking and listing of search results. In
response, artists have created alternative search engines, or perform or
ridicule specific features of Google’s search engine. Another recurring
motif in artistic representations of web searches is the act of
collecting or the formation of a collection. Camille Henrot’s
experimental film *Grosse Fatigue* (2013) frames web search as a form of
collecting and refers to Walter Benjamin's conceptualization of the
collector. When read alongside Kierkegaard’s notion of the relation
between faith and knowledge, I argue that *Grosse Fatigue* offers a
repositioning, a different relation, to the pervading discourse on the
centralised, monetized and monopolized structures of Google's search
engine. Further, by adopting a Kierkegaardian understanding of the act
of collecting as a passionate act, I argue that we can develop a way out
of search anxiety by moving towards what exceeds it.

In the final chapter I draw the preceding analyses together. I offer
explanations as to why specific algorithms trigger algorithmic anxiety,
and it provides reflections on how to live through it. The central
Kierkegaardian concept of this chapter, which ties together the concepts
discussed in the previous chapters, is ‘movement at the spot’. Movement
at the spot is a way to relate to possibility, and it will be framed as
a productive form of living through algorithmic anxiety. To move at the
spot is to make room for alternative imaginations and possibilities in
order to live with and through algorithmic anxiety. In this chapter, the
alternative imaginations of masks and camouflage (Chapter 2), hybrids
and specters (Chapter 3), collectors and collections (Chapter 4) will be
framed as figures of movement at the spot. These figures of motion show
that the algorithmic structures we inhabit and that inhibit us can be
opened by moving beyond the limitations detected by algorithms. They
point to the many contradictory relations within algorithmic culture and
represent different ways to relate to possibility, in order to live
through algorithmic anxiety.

[^intro_1]: A. Galloway, *Gaming: Essays on Algorithmic Culture*, Minnesota:
    Minnesota University Press, 2006.

[^intro_2]: T. Striphas, ‘Algorithmic Culture’, *European Journal of Cultural
    Studies*, 18.4-5 (2015): 395-412.

[^intro_3]: P. Dourish, ‘Algorithms and Their Others: Algorithmic Culture in
    Context’, *Big Data & Society* (2016):
    https://doi.org/10.1177/2053951716665128.

[^intro_4]: R. Kitchin, ‘Thinking Critically About and Researching
    Algorithms’, *Information, Communication & Society*, 1 (2016), 14.

[^intro_5]: Striphas, ‘Algorithmic Culture’, p. 395.

[^intro_6]: E.g. O. Halpern, *Beautiful Data: A History of Vision and Reason
    Since 1945*, London: Duke Press, 2014

[^intro_7]: Dourish, ‘Algorithms and Their Others’, 1.

[^intro_8]: Dourish, ‘Algorithms and Their Others’, 27.

[^intro_9]: T. Bucher, *If... Then: Algorithmic Power and Politics,* Oxford:
    Oxford University Press, 2018.

[^intro_10]: Bucher, *If... Then*, 3.

[^intro_11]: T. Gillespie, ‘Algorithm’, in *Digital Keywords: A Vocabulary of
    Information Society and Culture*, edited by B. Peters, Princeton:
    Princeton University Press, 2016, 26.

[^intro_12]: D. Beer, ‘The Social Power of Algorithms’, *Information,
    Communication & Society*, 1.20 (2017), 5.

[^intro_13]: E.g. Bucher, *If… Then*; J. Cheney-Lippold, *We Are Data:
    Algorithms and the Making of Our Digital Selves,* New York, NY: New
    York University Press, 2017; Kitchin, ‘Thinking Critically About and
    Researching Algorithms’; C. O’Neil, *Weapons of Math Destruction:
    How Big Data Increases Inequality and Threatens Democracy,* Largo:
    Crown Books, 2016; N. Diakopolous, *Algorithmic Accountability
    Reporting: On the Investigation of Black Boxes*, New York, NY:
    Columbia Journalism School, Tow Center for Digital Journalism, 2014;
    M. Lenglet, ‘Conflicting Codes and Codings: How Algorithmic Trading
    Is Reshaping Financial Regulation’, *Theory, Culture &
    Society*, 28.6 (2011): 44-66; D. Beer, ‘Power Through the Algorithm?
    Participatory Web Cultures and the Technological Unconscious’, *New
    Media & Society*, 11.6 (2009): 985–1002.

[^intro_14]: M. McLuhan, *Understanding Media: The Extensions of Man,* edited
    by W. Terrence Gordon, Berkeley: Gingko Press, 2003, 31.

[^intro_15]: Beer, ‘The Social Power of Algorithms’, 11.

[^intro_16]: E.g. A. MacKenzie, *Cutting Code: Software and Sociality*, New
    York: Peter Lang, 2006; L. Nakamura, ‘The Socioalgorithmics of Race:
    Sorting It Out in Jihad Worlds’, *The New Media of Surveillance*,
    edited by Kelly Gates and Shoshana Magnet, New York, NY: Routledge,
    2009; S. Browne, ‘Digital Epidermalization: Race, Identity and
    Biometrics’, *Critical Sociology,* 36.1 (2010); Diakopoulos,
    ‘Algorithmic Accountability Reporting’; M.B.N. Hansen,
    *Feed-Forward: On the Future of Twenty-First-Century Media*,
    Chicago: University of Chicago Press, 2015; Kitchin, ‘Thinking
    Critically About and Researching Algorithms’; O'Neil, *Weapons of
    Math Destruction*; Cheney-Lippold, *We Are Data*; R. Richardson, J.
    Schultz, and K. Crawford, ‘Dirty Data, Bad Predictions: How Civil
    Rights Violations Impact Police Data, Predictive Policing Systems,
    and Justice’, *New York University Law Review Online*, 2019,
    https://www.nyulawreview.org/online-features/dirty-data-bad-predictions-how-civil-rights-violations-impact-police-data-predictive-policing-systems-and-justice/.

[^intro_17]: S. Kierkegaard, *The Concept of Anxiety: A Simple Psychologically
    Oriented Deliberation in View of The Dogmatic Problem of Hereditary
    Sin*, edited and translated by A. Hannay, New York, NY: Liveright
    Publishing Company, 2014(1844).

[^intro_18]: S. Kierkegaard, *The Concept of Anxiety*, 259.

[^intro_19]: S. Kierkegaard, *The Concept of Anxiety*, 257.

[^intro_20]: S. Kierkegaard, *The Concept of Anxiety*, 257.

[^intro_21]: S. Kierkegaard, *The Concept of Anxiety*, 256.

[^intro_22]: S. Kierkegaard, *The Concept of Anxiety*, 86.

[^intro_23]: S. Kierkegaard, *The Concept of Anxiety*, 255.

[^intro_24]: S. Kierkegaard, *The Concept of Anxiety*, 257. Kierkegaard
    experienced much suffering. By the time he was 21 years of age, he
    had lost his mother and five of his six siblings. His father would
    die a few years later. He also suffered from a spinal disease,
    epilepsy, and from what was then called melancholia.

[^intro_25]: M. Ruefle, *Madness, Rack, and Honey,* Seattle and New York: Wave
    Books, 2012, 112.

[^intro_26]: S. Kierkegaard, *The Present Age: On the Death of Rebellion*,
    translated by A. Dru, New York and London: Harper Perennial,
    2010(1846).

[^intro_27]: S. Ngai, *Ugly Feelings,* Cambridge: Harvard University Press,
    2005, 228.

[^intro_28]: Ngai, *Ugly Feelings*, 25.

[^intro_29]: G. Deleuze, ‘Postscript on the Societies of Control’, *October*,
    59 (1992): 3-7.

[^intro_30]: A. Galloway, *Protocol: How Control Exists After
    Decentralization*, Cambridge, MA: The MIT Press, 2004.

[^intro_31]: M. Bal, *Travelling Concepts in the Humanities: A Rough Guide,*
    Toronto: University of Toronto Press, 2002.
